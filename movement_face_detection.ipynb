{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movement_face_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaledMC/Learning-Artificial-Vision/blob/master/movement_face_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jZNs9ytezI67",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Video features detection"
      ]
    },
    {
      "metadata": {
        "id": "19_rcz1K4nta",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVctjCYb41Np",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get('https://raw.githubusercontent.com/JaledMC/Learning-Artificial-Vision/master/images/car.mp4')\n",
        "with open('car.mp4', 'wb') as f:\n",
        "    f.write(response.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gSGfuv45vzcu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Movement object extraction\n",
        "\n",
        "Movement object segmentation over a static background is a clasical problem. At first, it can be enought subtracting two sequential frames, changes in ambient light or shadows can produce noises. "
      ]
    },
    {
      "metadata": {
        "id": "5zrRnHl2v3XF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('car.mp4')\n",
        "# MOG2 substactor\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "while(1):\n",
        "    ret, frame = cap.read()\n",
        "    # obtain the foreground mask\n",
        "    fgmask = fgbg.apply(frame)\n",
        "    \n",
        "    cv2.imshow('fgmask',frame)\n",
        "    cv2.imshow('frame',fgmask)   \n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "    \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Sm3iBanv3cT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Viola-James Haar cascade\n",
        "\n",
        "Viola-James Haar cascade is used typically for face detection. One good thing of Viola-Jones algorithm is its small size: xml files of trained features barely wheights a couple of MB. Thats means that with a normal 4GB RAM we can clasify thousands of objects. [We can use xml for other people](# multiple cascades: https://github.com/Itseez/opencv/tree/master/data/haarcascades), or [train the algorithm to detect our objects](https://pythonprogramming.net/haar-cascade-object-detection-python-opencv-tutorial/), but their training are slow.\n",
        "\n",
        "Haar cascades are not too fast, because they have to run over all the images multiple times, with different kernels size. To speed up the program, for complex objects like cars or faces, it's better to use hierarchical segmentation: first detect the face, and over the ROI of the face, detect the eyes, mounth...\n",
        "\n",
        "Training a Haar Cascade it's time consuming. We can find trained examples [here](#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml).\n",
        "\n",
        "First, download the xml file and create the cascade classifier."
      ]
    },
    {
      "metadata": {
        "id": "m_bWdI676m25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import Haar cascades database for face and eyes, and instace the detector objects\n",
        "import requests\n",
        "# Create the face detector\n",
        "response = requests.get('https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml')\n",
        "with open('haarcascade_frontalface_default.xml', 'wb') as f:\n",
        "    f.write(response.content)\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "# Create the eye detector\n",
        "response = requests.get('https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_eye.xml')\n",
        "with open('haarcascade_frontalface_default.xml', 'wb') as f:\n",
        "    f.write(response.content)\n",
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-K-hAj-v3gd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Detect the position and area of faces in the image: image, scaling step, pixel number for the area\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    # plot the square rectangle and select the ROI\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "        roi_gray = gray[y:y + h, x:x + w]\n",
        "        roi_color = img[y:y + h, x:x + w]\n",
        "        # detect the position and area of eyes on the roi\n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "        for (ex, ey, ew, eh) in eyes:\n",
        "            cv2.rectangle(roi_color,(ex,ey),(ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow('img', img)\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UXqfa2RMAcbo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can detect eyes too."
      ]
    },
    {
      "metadata": {
        "id": "An0OrMVwwBWm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "while True:\n",
        "    ret, img = cap.read()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Detect the position and area of eyes in the image: image, scaling step, pixel number for the area\n",
        "    eyes = eye_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    # plot the square rectangle \n",
        "    for (x,y,w,h) in eyes:\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "    cv2.imshow('img', img)\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}