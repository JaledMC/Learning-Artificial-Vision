{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_thresholding_gradients.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaledMC/Learning-Artificial-Vision/blob/master/video_thresholding_gradients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zYjIIpdxJ_QD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Video thresholding\n",
        "\n",
        "Thresholds are used to recognice borders and edges. They must be applied in a gray image, and return a binary frame that we can use as a mask for segmentation.\n",
        "\n",
        "When is difficult to find the threshold value, it is possible to make a previous analisys and adjust the ROI, removing the rest of the image, or apply other more complex algorithm like watershed on the unknow area.\n",
        "\n",
        "First import the libraries."
      ]
    },
    {
      "metadata": {
        "id": "Hc-9My7kKlmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQIh3HVPT7dl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(1)\n",
        " \n",
        "while(True):\n",
        "    _, frame = cap.read()\n",
        "    frame2gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    # With binary image, we can select the threshold level, the output pixels value, or if we want an inverse mask.\n",
        "    # image, threshold, outMaxValue, type. If only change one value side is desired, use 'TRUNC'or'TOZERO'\n",
        "    _, th1 = cv2.threshold(frame2gray, 153, 255, cv2.THRESH_BINARY) \n",
        "    # Binary thresholds don't work well for complex images when we want to identify edges. An adaptative thresholds can works better in that case.\n",
        "    # image, outMaxValue, type, binary finish, area size, multiply factor\n",
        "    th2 = cv2.adaptiveThreshold(frame2gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
        "    # When we don't know the threshold value, Otsu filters finds a value for us. It uses the histogram to detect a value between spikes.\n",
        "    # image, threshold, outMaxValue, type. Otsu calculate threshold value, because of that we can put the value to 0\n",
        "    _, th3 = cv2.threshold(frame2gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    # We can select the pixels between two values with in range for multilevel thresholding\n",
        "    mask2 = cv2.inRange(frame2gray, 40, 90)\n",
        "    final_frame = cv2.hconcat((th1, th2, th3, mask2))\n",
        "    cv2.imshow('frame', final_frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tItfmE2qMCb9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Image gradients\n",
        "\n",
        "OpenCV provides three types of gradient filters or High-pass filters, Sobel, Scharr and Laplacian. They improve the edges detection. Canny filter is one of the most used.\n"
      ]
    },
    {
      "metadata": {
        "id": "XJnkb7DfV30F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(1)\n",
        " \n",
        "while(True):\n",
        "    _, frame = cap.read()\n",
        "    edges = cv2.Canny(frame, 100, 200) # src, 1st threshold, 2nd threshold\n",
        "    laplacian = cv2.Laplacian(frame, cv2.CV_64F) # src, output type (for positive and negative transitions, more than 8b)\n",
        "    sobelx = cv2.Sobel(frame, cv2.CV_64F, 0, 1, ksize=5)  # src,output type, scaling factor, delta factor, kernel size\n",
        "    sobely = cv2.Sobel(frame, cv2.CV_64F, 1, 1,ksize=5)  # src,output type, scaling factor, delta factor, kernel size\n",
        "    # https://en.wikipedia.org/wiki/Canny_edge_detector\n",
        "    \n",
        "    cv2.imshow('frame', edges)\n",
        "    cv2.imshow('frame2', laplacian)\n",
        "    cv2.imshow('frame3', sobelx)\n",
        "    cv2.imshow('frame4', sobely)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}